{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44924102-388a-4ce0-92d5-ede3e2579a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944f1b14-dd73-4e46-87ec-632b34692b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha cargado correctamente la página de la MARCA\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Se ha cargado correctamente la página de la MARCA\n",
      "Guardados 1000 enlaces hasta el momento.\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Se ha cargado correctamente la página de la MARCA\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Se ha cargado correctamente la página de la MARCA\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Se ha cargado correctamente la página de la MARCA\n",
      "Guardados 2000 enlaces hasta el momento.\n",
      "Guardados 3000 enlaces hasta el momento.\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Se ha cargado correctamente la página de la MARCA\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Se ha cargado correctamente la página de la MARCA\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Se ha cargado correctamente la página de la MARCA\n",
      "Guardados 4000 enlaces hasta el momento.\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Se ha cargado correctamente la página de la MARCA\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Se ha cargado correctamente la página de la MARCA\n",
      "Guardados 5000 enlaces hasta el momento.\n",
      "No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\n",
      "Tarea terminada correctamente, 5232 enlaces de carros fueron almacenados!!!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta del perfil de Firefox\n",
    "profile_path = r'C:\\Users\\herna\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\6mccoojc.automation'\n",
    "\n",
    "goptions = webdriver.FirefoxOptions()\n",
    "goptions.add_argument('--profile')\n",
    "goptions.add_argument(profile_path)\n",
    "\n",
    "driver = webdriver.Firefox(options=goptions)\n",
    "filename = f\"Libro_Enlace.xlsx\"\n",
    "df_marcas = pd.read_excel(filename)\n",
    "enlaces_marcas = df_marcas[\"enlaces\"]\n",
    "\n",
    "enlaces_count = 0\n",
    "enlaces_set_autos = set()\n",
    "enlaces_totales = set()  # Conjunto para almacenar todos los enlaces\n",
    "marcas_visitadas = set()\n",
    "verificador = False\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if len(marcas_visitadas) == len(df_marcas):\n",
    "            break\n",
    "        time.sleep(1)\n",
    "        for enlace in enlaces_marcas:\n",
    "            time.sleep(1)\n",
    "            if enlace not in marcas_visitadas:\n",
    "                print(\"Se ha cargado correctamente la página de la MARCA\")\n",
    "                marcas_visitadas.add(enlace)\n",
    "                driver.get(enlace)\n",
    "                time.sleep(2)\n",
    "\n",
    "            while True:\n",
    "                links_autos = driver.find_elements(By.XPATH, '//div[@class=\"card-info card-content\"]/a')\n",
    "                \n",
    "                for link in links_autos:\n",
    "                    try:\n",
    "                        article_link = link.get_attribute(\"href\")\n",
    "                        enlaces_set_autos.add(article_link)\n",
    "                        enlaces_totales.add(article_link)  # Añadir a enlaces_totales\n",
    "                        enlaces_count += 1\n",
    "\n",
    "                        # Guardar los enlaces cada 1000\n",
    "                        if enlaces_count % 1000 == 0:\n",
    "                            df_temp = pd.DataFrame({\"enlace_auto\": list(enlaces_set_autos)})\n",
    "                            fecha_actual = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "                            df_temp.to_csv(f'dataset_links_patiotuerca_{enlaces_count}_{fecha_actual}.csv', index=False)\n",
    "                            enlaces_set_autos.clear()\n",
    "                            print(f\"Guardados {enlaces_count} enlaces hasta el momento.\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(\"Error al encontrar enlaces de autos.\")\n",
    "                        continue\n",
    "        \n",
    "                try:\n",
    "                    # Hacer clic en el botón \"Cargar más\" si está presente\n",
    "                    btn_cargar_mas = driver.find_element(By.XPATH, '/html/body/div[2]/div/article/div[7]/div[2]/div/a')\n",
    "                    btn_cargar_mas.click()\n",
    "                    time.sleep(1.25)  # Espera 1.25 segundos después de hacer clic en el botón \"Cargar más\"\n",
    "                except Exception as e:\n",
    "                    print(\"No se encontró el botón 'Cargar más' o se alcanzó el final de la página.\")\n",
    "                    break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Se ha producido un error: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Guardar todos los enlaces recolectados\n",
    "    if enlaces_totales:\n",
    "        df_final = pd.DataFrame({\"enlace_auto\": list(enlaces_totales)})\n",
    "        fecha_actual = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        df_final.to_csv(f'dataset_links_patiotuerca_completo.csv', index=False)\n",
    "    print(f\"Tarea terminada correctamente, {enlaces_count} enlaces de carros fueron almacenados!!!\")\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b3466ce-0c3f-4cf2-9b39-7d6769ac5386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:   9%|▉         | 450/5075 [1:29:12<7:37:16,  5.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 450 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  18%|█▊        | 900/5075 [2:57:40<24:42:11, 21.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 900 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  27%|██▋       | 1350/5075 [4:28:16<6:42:33,  6.48s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 1350 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  35%|███▌      | 1800/5075 [5:40:46<5:57:12,  6.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 1800 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  37%|███▋      | 1884/5075 [6:00:08<90:51:14, 102.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en el enlace 1883: Message: Navigation timed out after 300000 ms\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "TimeoutError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:740:5\n",
      "bail@chrome://remote/content/marionette/sync.sys.mjs:211:19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  44%|████▍     | 2251/5075 [7:15:41<12:32:28, 15.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 2250 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  53%|█████▎    | 2701/5075 [8:31:52<5:21:35,  8.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 2700 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  62%|██████▏   | 3151/5075 [10:07:49<4:58:14,  9.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 3150 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  71%|███████   | 3601/5075 [11:48:36<5:06:54, 12.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 3600 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  80%|███████▉  | 4051/5075 [13:38:45<4:45:25, 16.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 4050 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  89%|████████▊ | 4501/5075 [15:15:13<3:59:35, 25.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 4500 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces:  98%|█████████▊| 4951/5075 [16:57:29<19:56,  9.65s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados 4950 enlaces hasta el momento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando enlaces: 100%|██████████| 5075/5075 [17:21:43<00:00, 12.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los datos guardados, total de 5074 enlaces procesados.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Ruta del perfil de Firefox\n",
    "profile_path = r'C:\\Users\\ADA_LAB01\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\g45nbskz.automation'\n",
    "# profile_path = r'C:\\Users\\herna\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\6mccoojc.automation'\n",
    "\n",
    "# Configuración de opciones de Firefox\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.set_preference(\"profile\", profile_path)\n",
    "\n",
    "# Inicializar el controlador de Firefox con las opciones especificadas\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "# Nombre del archivo de entrada\n",
    "filename = 'dataset_links_patiotuerca_completo.csv'\n",
    "\n",
    "carros_count = 0\n",
    "data_list = []\n",
    "all_data = []  # Lista para almacenar todos los datos\n",
    "\n",
    "# Definir fecha de recolección antes del bloque try\n",
    "fecha_recoleccion = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def get_element_text(by, value):\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((by, value)))\n",
    "        return element.text\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        return \"No disponible\"\n",
    "\n",
    "def get_element_attribute(by, value, attribute):\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((by, value)))\n",
    "        return element.get_attribute(attribute)\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        return \"No disponible\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(filename)\n",
    "    enlaces = df['enlace_auto']\n",
    "\n",
    "    for i, enlace in tqdm(enumerate(enlaces), total=len(enlaces), desc='Procesando enlaces'):\n",
    "        try:\n",
    "            driver.get(enlace)\n",
    "            \n",
    "            marca = get_element_text(By.XPATH, '//p[small[contains(text(),\"Marca\")]]/span')\n",
    "            modelo = get_element_text(By.XPATH, '//p[small[contains(text(),\"Modelo\")]]/span')\n",
    "            nombre = get_element_text(By.XPATH, '//*[@id=\"galleryHeight\"]/div/div[2]/div/div/div[1]/h2')\n",
    "            precio = get_element_attribute(By.XPATH, '//meta[@itemprop=\"price\"]', \"content\")\n",
    "            anio = get_element_text(By.XPATH, '//*[@id=\"summary\"]/div[2]/div[1]')\n",
    "            kilometraje = get_element_attribute(By.XPATH, '//meta[@itemprop=\"mileageFromOdometer\"]', \"content\")\n",
    "            transmision = get_element_text(By.XPATH, '//p[small[contains(text(),\"Transmisión\")]]/span')\n",
    "            combustible = get_element_text(By.XPATH, '//p[small[contains(text(),\"Combustible\")]]/span')\n",
    "            ciudad = get_element_text(By.XPATH, '//*[@id=\"summary\"]/div[2]/div[2]')\n",
    "            cilindraje = get_element_text(By.XPATH, '//p[small[contains(text(),\"Motor(cilindraje)\")]]/span')\n",
    "            traccion = get_element_text(By.XPATH, '//p[small[contains(text(),\"Tracción\")]]/span')\n",
    "            color = get_element_text(By.XPATH, '//p[small[contains(text(),\"Color\")]]/span')\n",
    "\n",
    "            # Actualizar fecha de recolección dentro del bloque try\n",
    "            fecha_recoleccion = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            carros_link = enlace\n",
    "            \n",
    "            data = {\n",
    "                'Marca': marca,\n",
    "                'Modelo': modelo,\n",
    "                'Nombre': nombre,\n",
    "                'Precio': precio,\n",
    "                'Anio': anio,\n",
    "                'Kilometraje': kilometraje,\n",
    "                'Transmision': transmision,\n",
    "                'Combustible': combustible,\n",
    "                'Ciudad': ciudad,\n",
    "                'Cilindraje': cilindraje,\n",
    "                'Traccion': traccion,\n",
    "                'Color': color,\n",
    "                'Fecha de recoleccion': fecha_recoleccion,\n",
    "                'Link': carros_link\n",
    "            }\n",
    "            \n",
    "            data_list.append(data)\n",
    "            all_data.append(data)  # También añadir a all_data\n",
    "            \n",
    "            carros_count += 1\n",
    "\n",
    "            # Guardar cada 750 enlaces procesados\n",
    "            if carros_count % 450 == 0:\n",
    "                df_temp = pd.DataFrame(data_list)\n",
    "                df_temp.to_csv(f'datos_patioTuerca_{carros_count}.csv', index=False)\n",
    "                data_list.clear()\n",
    "                print(f'Guardados {carros_count} enlaces hasta el momento.')\n",
    "                    \n",
    "        except WebDriverException as e:\n",
    "            print(f\"Error en el enlace {i}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Se ha producido un error: {str(e)}\")\n",
    "finally:\n",
    "    # Guardar los datos restantes\n",
    "    if all_data:\n",
    "        df_final = pd.DataFrame(all_data)\n",
    "        df_final.to_csv(f'datos_patioTuerca_completo.csv', index=False)\n",
    "        print(f'Todos los datos guardados, total de {carros_count} enlaces procesados.')\n",
    "\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e1b9bb2-bc2e-49bb-9919-4968cca5c205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos_patioTuerca_Final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Cargar el archivo CSV final\n",
    "final_data = pd.read_csv(f\"datos_patioTuerca_completo.csv\")\n",
    "\n",
    "# Extraer el identificador numérico de la URL\n",
    "final_data['identificador'] = final_data['Link'].apply(lambda x: re.findall(r'\\d+', x)[-1] if pd.notnull(x) else '')\n",
    "\n",
    "final_data = final_data.replace(\"No disponible\", \"\")\n",
    "final_data['Ciudad'] = final_data['Ciudad'].str.split('\\n').str[-1]\n",
    "\n",
    "# Limpiar la columna 'Anio' para que queden solo valores numéricos\n",
    "final_data['Anio'] = final_data['Anio'].str.extract('(\\d+)')\n",
    "\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "new_file_path = 'datos_patioTuerca_Final.csv'\n",
    "final_data.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5317d731-5b74-4aa4-9a48-0607c18ba05c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos_patioTuerca_Final_actualizado1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV final\n",
    "final_data = pd.read_csv(\"datos_patioTuerca_Final.csv\")\n",
    "\n",
    "# Crear una nueva columna llamada 'Tiempo de uso' calculando la diferencia entre 2024 y el año de fabricación\n",
    "final_data['Tiempo de uso'] = 2024 - final_data['Anio']\n",
    "# Multiplicar la columna 'Precio' por 1000\n",
    "final_data['Precio'] = final_data['Precio'] * 1000\n",
    "\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "new_file_path = 'datos_patioTuerca_Final_actualizado1.csv'\n",
    "final_data.to_csv(new_file_path, index=False)\n",
    "\n",
    "# Imprimir la ruta del nuevo archivo para confirmar que se ha guardado correctamente\n",
    "print(new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e30f62-7c97-4e0b-a2e8-d7aebf9107d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xed in position 28: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Cargar el archivo CSV final\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m final_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m240606 - Para llenarse12.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Update the 'Precio' column by multiplying by 1000\u001b[39;00m\n\u001b[0;32m      7\u001b[0m datos_relevan\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:550\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:639\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:2021\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xed in position 28: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Cargar el archivo CSV final\n",
    "final_data = pd.read_csv(f\"240606 - Para llenarse12.csv\")\n",
    "# Update the 'Precio' column by multiplying by 1000\n",
    "datos_relevan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92456f34-46df-450a-ad62-03f242887333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV final\n",
    "final_data = pd.read_csv(\"datos_patioTuerca_Final.csv\")\n",
    "\n",
    "# Renombrar las columnas de 'datos_patio'\n",
    "datos_patio.rename(columns={\n",
    "    'identificador': 'Identificador',\n",
    "    'Nombre': 'Nombre del vehículo',\n",
    "    'Precio': 'Precio',\n",
    "    'Anio': 'Año',\n",
    "    'Kilometraje': 'Kilometraje',\n",
    "    'Transmision': 'Transmision',\n",
    "    'Cilindraje': 'Cilindraje',\n",
    "    'Traccion': 'Traccion',\n",
    "    'Color': 'Color',\n",
    "    'Combustible': 'Combustible',\n",
    "    'Ciudad': 'Provincia',\n",
    "    'Tiempo de uso': 'Tiempo_uso',\n",
    "    'Fecha de recoleccion': 'Fecha Dato',\n",
    "}, inplace=True)\n",
    "\n",
    "# Seleccionar columnas relevantes de 'datos_patio'\n",
    "datos_relevant = datos_patio[[\n",
    "    'Identificador', 'Nombre del vehículo', 'Marca', 'Modelo', 'Precio', 'Año', 'Kilometraje',\n",
    "    'Transmision', 'Cilindraje', 'Traccion', 'Color', 'Combustible', 'Provincia', 'Tiempo_uso', \n",
    "    'Fecha Dato'\n",
    "]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Multiplicar la columna 'Precio' por 1000\n",
    "datos_relevant['Precio'] = datos_relevant['Precio'] * 1000\n",
    "\n",
    "# Actualizar el DataFrame 'final_data' con las columnas relevantes\n",
    "# Crear 'datos_llenado' copiando de 'final_data'\n",
    "datos_llenado = final_data.copy()\n",
    "\n",
    "# Llenar el DataFrame vacío con los datos relevantes\n",
    "for column in datos_relevant.columns:\n",
    "    datos_llenado[column] = datos_relevant[column]\n",
    "\n",
    "# Agregar la columna 'Fuente' desde 'datos_patio'\n",
    "datos_llenado['Fuente'] = datos_patio['Link']\n",
    "# Display the first few rows to verify the new column\n",
    "df.head()\n",
    "\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "new_file_path = 'datos_patioTuerca_Final.csv'\n",
    "datos_llenado.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69480b99-cb87-457f-95c3-a28c3e4e50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV actualizado\n",
    "file_path = 'datos_patioTuerca_Final_actualizado.csv'\n",
    "datos_patio = pd.read_csv(file_path)\n",
    "\n",
    "# Renombrar las columnas\n",
    "datos_patio.rename(columns={\n",
    "    'identificador': 'Identificador',\n",
    "    'Nombre': 'Nombre del vehículo',\n",
    "    'Precio': 'Precio',\n",
    "    'Anio': 'Año',\n",
    "    'Kilometraje': 'Kilometraje',\n",
    "    'Transmision': 'Transmision',\n",
    "    'Cilindraje': 'Cilindraje',\n",
    "    'Traccion': 'Traccion',\n",
    "    'Color': 'Color',\n",
    "    'Combustible': 'Combustible',\n",
    "    'Ciudad': 'Provincia',\n",
    "    'Tiempo de uso': 'Tiempo_uso',\n",
    "    'Fecha de recoleccion': 'Fecha Dato',\n",
    "}, inplace=True)\n",
    "\n",
    "# Seleccionar columnas relevantes\n",
    "datos_relevant = datos_patio[[\n",
    "    'Identificador', 'Nombre del vehículo', 'Marca', 'Modelo', 'Precio', 'Año', 'Kilometraje',\n",
    "    'Transmision', 'Cilindraje', 'Traccion', 'Color', 'Combustible', 'Provincia', 'Tiempo_uso', \n",
    "    'Fecha Dato'\n",
    "]]\n",
    "\n",
    "# Multiplicar la columna 'Precio' por 1000\n",
    "datos_relevant['Precio'] = datos_relevant['Precio'] * 1000\n",
    "\n",
    "# Crear 'datos_llenado' copiando de 'datos_patio'\n",
    "datos_llenado = datos_patio.copy()\n",
    "\n",
    "# Llenar el DataFrame vacío con los datos relevantes\n",
    "for column in datos_relevant.columns:\n",
    "    datos_llenado[column] = datos_relevant[column]\n",
    "\n",
    "# Agregar la columna 'Fuente' desde 'datos_patio'\n",
    "datos_llenado['Fuente'] = datos_patio['Link']\n",
    "\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "new_file_path = 'datos_patioTuerca_Final_290606.csv'\n",
    "datos_llenado.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce8b2d7e-2714-4b7d-adf8-c8c418d242cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos_patioTuerca_Final_290606.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herna\\AppData\\Local\\Temp\\ipykernel_2252\\596579111.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datos_relevant['Precio'] = datos_relevant['Precio'] * 1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV actualizado\n",
    "file_path = 'datos_patioTuerca_Final_actualizado.csv'\n",
    "datos_patio = pd.read_csv(file_path)\n",
    "\n",
    "# Renombrar las columnas\n",
    "datos_patio.rename(columns={\n",
    "    'identificador': 'Identificador',\n",
    "    'Nombre': 'Nombre del vehículo',\n",
    "    'Precio': 'Precio',\n",
    "    'Anio': 'Año',\n",
    "    'Kilometraje': 'Kilometraje',\n",
    "    'Transmision': 'Transmision',\n",
    "    'Cilindraje': 'Cilindraje',\n",
    "    'Traccion': 'Traccion',\n",
    "    'Color': 'Color',\n",
    "    'Combustible': 'Combustible',\n",
    "    'Ciudad': 'Provincia',\n",
    "    'Tiempo de uso': 'Tiempo_uso',\n",
    "    'Fecha de recoleccion': 'Fecha Dato',\n",
    "}, inplace=True)\n",
    "\n",
    "# Seleccionar columnas relevantes\n",
    "datos_relevant = datos_patio[[\n",
    "    'Identificador', 'Nombre del vehículo', 'Marca', 'Modelo', 'Precio', 'Año', 'Kilometraje',\n",
    "    'Transmision', 'Cilindraje', 'Traccion', 'Color', 'Combustible', 'Provincia', 'Tiempo_uso', \n",
    "    'Fecha Dato'\n",
    "]]\n",
    "\n",
    "# Multiplicar la columna 'Precio' por 1000\n",
    "datos_relevant['Precio'] = datos_relevant['Precio'] * 1000\n",
    "\n",
    "# Crear 'datos_llenado' copiando de 'datos_patio'\n",
    "datos_llenado = datos_patio.copy()\n",
    "\n",
    "# Llenar el DataFrame vacío con los datos relevantes\n",
    "for column in datos_relevant.columns:\n",
    "    datos_llenado[column] = datos_relevant[column]\n",
    "\n",
    "# Agregar la columna 'Fuente' desde 'datos_patio'\n",
    "datos_llenado['Fuente'] = datos_patio['Link']\n",
    "\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "new_file_path = 'datos_patioTuerca_Final_290606.csv'\n",
    "datos_llenado.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(new_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043aae69-7336-474c-abc7-146f23cf4b99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240606 - Para llenarse2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "datos_patio = pd.read_csv('datos_patioTuerca_Final_actualizado1.csv')\n",
    "\n",
    "# Cargar el archivo de Excel\n",
    "archivo_excel = pd.ExcelFile('240606 - Para llenarse.xlsx')\n",
    "\n",
    "# Leer los datos de la primera hoja del archivo de Excel\n",
    "datos_excel = archivo_excel.parse('Sheet1')\n",
    "\n",
    "# Renombrar columnas en datos_patio para que coincidan con el DataFrame de destino\n",
    "datos_patio.rename(columns={\n",
    "    'identificador': 'Identificador',\n",
    "    'Nombre': 'Nombre del vehículo',\n",
    "    'Precio': 'Precio',\n",
    "    'Anio': 'Año',\n",
    "    'Kilometraje': 'Kilometraje',\n",
    "    'Transmision': 'Transmision',\n",
    "    'Cilindraje': 'Cilindraje',\n",
    "    'Traccion': 'Traccion',\n",
    "    'Color': 'Color',\n",
    "    'Combustible': 'Combustible',\n",
    "    'Ciudad': 'Provincia',\n",
    "    'Tiempo de uso': 'Tiempo_uso',\n",
    "    'Fecha de recoleccion': 'Fecha Dato',\n",
    "    'Link': 'Fuente'  # Añadir Link como Fuente\n",
    "}, inplace=True)\n",
    "\n",
    "# Seleccionar las columnas relevantes para que coincidan con el DataFrame de destino\n",
    "datos_relevant = datos_patio[[\n",
    "    'Identificador', 'Nombre del vehículo', 'Marca', 'Modelo', 'Precio', 'Año', 'Kilometraje',\n",
    "    'Transmision', 'Cilindraje', 'Traccion', 'Color', 'Combustible', 'Provincia', 'Tiempo_uso', \n",
    "    'Fecha Dato', 'Fuente'  # Añadir Fuente\n",
    "]]\n",
    "\n",
    "# Crear una copia del DataFrame de destino\n",
    "datos_llenado = datos_excel.copy()\n",
    "\n",
    "# Rellenar el DataFrame vacío con los datos relevantes\n",
    "for column in datos_relevant.columns:\n",
    "    datos_llenado[column] = datos_relevant[column]\n",
    "\n",
    "datos_llenado['Año recolección'] = 2024\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "new_file_path = '240606 - Para llenarse2.csv'\n",
    "datos_llenado.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751d6362-c231-41d7-a6c4-b6e4769c599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Rutas de los archivos CSV\n",
    "file_paths = [\n",
    "    \"AutosOK.csv\",\n",
    "    \"datos_fullautos.csv\",\n",
    "    \"DF_AZ_2024-06-11.csv\",\n",
    "    \"240606 - Para llenarse2.csv\"\n",
    "]\n",
    "\n",
    "# Leer el archivo de referencia para las columnas\n",
    "df_reference = pd.read_csv(\"DF_AZ_2024-06-11.csv\", encoding='latin1', on_bad_lines='skip')\n",
    "\n",
    "# Obtener las columnas del DataFrame de referencia\n",
    "reference_columns = df_reference.columns\n",
    "\n",
    "# Leer los CSVs con encoding 'latin1' y manejar líneas incorrectas, manteniendo solo las columnas de referencia\n",
    "dataframes = []\n",
    "errors = []\n",
    "\n",
    "for file in file_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='latin1', on_bad_lines='skip')\n",
    "        df = df[reference_columns]  # Filtrar las columnas\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        errors.append((file, str(e)))\n",
    "\n",
    "# Concatenar los DataFrames en uno solo\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame combinado en un nuevo archivo CSV\n",
    "combined_df.to_csv(\"240606 - Para llenarse3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7274a8e-c50e-4582-99c8-d69b744cd7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
